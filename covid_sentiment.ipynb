{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tweepy'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/3l/yzh9j02x7bxd463cl1x0_2lh0000gn/T/ipykernel_34543/1309497472.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0;32mimport\u001B[0m \u001B[0mtweepy\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mtw\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mos\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mpandas\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mpd\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0mconsumer_key\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m\"YYBMfccNfa4qClAw8CUT1DDGE\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'tweepy'"
     ]
    }
   ],
   "source": [
    "import tweepy as tw\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "consumer_key = \"Your own key\"\n",
    "consumer_secret = \"Your own secret\"\n",
    "access_token = \"Your own token\"\n",
    "access_token_secret = \"Your own secret\"\n",
    "\n",
    "# Creating the authentication object\n",
    "auth = tw.OAuthHandler(consumer_key, consumer_secret)\n",
    "# Setting your access token and secret\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "# Creating the API object while passing in auth information\n",
    "api = tw.API(auth)\n",
    "\n",
    "cursor = tw.Cursor(api.search, lang=\"en\", q=\"COVID\", tweet_mode=\"extended\").items(50)\n",
    "\n",
    "tweets = []\n",
    "time = []\n",
    "likes = []\n",
    "source = []\n",
    "retweeted = []\n",
    "\n",
    "for i in cursor:\n",
    "    tweets.append(i.full_text)\n",
    "    time.append(i.created_at)\n",
    "    source.append(i.source)\n",
    "    likes.append(i.favorite_count)\n",
    "    retweeted.append(i.retweet_count)\n",
    "\n",
    "\n",
    "df = pd.DataFrame({'tweets': tweets, 'time': time, 'source': source, 'likes': likes, 'retweeted': retweeted})\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "import seaborn as sns\n",
    "list_of_sentences = [sentence for sentence in df.tweets]\n",
    "lines = []\n",
    "for sentence in list_of_sentences:\n",
    "    words = sentence.split()\n",
    "    for w in words:\n",
    "        lines.append(w)\n",
    "\n",
    "lines = [re.sub(r'[^A-Za-z0-9]+', '', x) for x in lines]\n",
    "\n",
    "lines2 = []\n",
    "\n",
    "for word in lines:\n",
    "    if word != '':\n",
    "        lines2.append(word)\n",
    "\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "s_stemmer = SnowballStemmer(language='english')\n",
    "\n",
    "stem = []\n",
    "for word in lines2:\n",
    "    stem.append(s_stemmer.stem(word))\n",
    "\n",
    "stem2 = []\n",
    "for word in stem:\n",
    "    if word not in nlp.Defaults.stop_words:\n",
    "        stem2.append(word)\n",
    "\n",
    "df2 = pd.DataFrame(stem2)\n",
    "df2 = df2[0].value_counts()\n",
    "\n",
    "df2 = df2[:20,]\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.barplot(df2.values, df2.index, alpha=1)\n",
    "plt.title('Top Words Overall')\n",
    "plt.ylabel('Word from Tweet', fontsize=12)\n",
    "plt.xlabel('Count of Words', fontsize=12)\n",
    "plt.show()\n",
    "\n",
    "def show_ents(doc):\n",
    "    if doc.ents:\n",
    "        for ent in doc.ents:\n",
    "            print(ent.text + ' - ' + ent.label_ + ' - ' + str(spacy.explain(ent.label_)))\n",
    "\n",
    "str1 = \" \"\n",
    "stem2 = str1.join(lines2)\n",
    "stem2 = nlp(stem2)\n",
    "label = [(X.text, X.label_) for X in stem2.ents]\n",
    "\n",
    "df6 = pd.DataFrame(label, columns= ['Word', 'Entity'])\n",
    "df7 = df6.where(df6['Entity'] == 'ORG')\n",
    "df7 = df7['Word'].value_counts()\n",
    "\n",
    "dfx = df7[:20,]\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.barplot(dfx.values, dfx.index, alpha=1)\n",
    "plt.title('Top Organizations Mentioned')\n",
    "plt.ylabel('Word from Tweet', fontsize=12)\n",
    "plt.xlabel('Count of Words', fontsize=12)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "#https://www.youtube.com/watch?v=bNDRiaFyLrs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}